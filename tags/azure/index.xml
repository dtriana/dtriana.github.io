<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Azure on David Triana</title><link>https://davidtriana.com/tags/azure/</link><description>Recent content in Azure on David Triana</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>david@davidtriana.com (David Triana)</managingEditor><webMaster>david@davidtriana.com (David Triana)</webMaster><copyright>2022 David Triana All rights reserved</copyright><lastBuildDate>Fri, 20 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://davidtriana.com/tags/azure/index.xml" rel="self" type="application/rss+xml"/><item><title>Reusing Javascript in Logic Apps Standard</title><link>https://davidtriana.com/posts/2024/logic-app-reuse-javascript/</link><pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/logic-app-reuse-javascript/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>What I&amp;rsquo;m about to describe is more like a &amp;ldquo;because I can&amp;rdquo; approach than a recommended technique. The reason for this POST is &lt;a href="https://stackoverflow.com/a/67565101">a StackOverflow answer&lt;/a> claiming that &amp;ldquo;if we want to run node code with some third-party packages, we can only use Azure function action&amp;rdquo;.&lt;/p>
&lt;p>I found this answer while looking for a way to get a SHA-256 for an object in a Logic Apps Standard workflow, and yes, the function action is a good alternative, the same with a full function app, I however share the feeling from the author of the question, &lt;a href="https://stackoverflow.com/questions/67556776/azure-logic-apps-generated-hmac-sha256-method-signature#comment119465221_67565101">&amp;ldquo;I just couldn&amp;rsquo;t believe I had to go to such lengths&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>The limitation in the &lt;a href="https://learn.microsoft.com/en-us/azure/logic-apps/add-run-javascript?tabs=standard">in-line javascript action&lt;/a> is there, it &amp;ldquo;Doesn&amp;rsquo;t support the require() function for running JavaScript.&amp;rdquo;, however, what &amp;lsquo;require&amp;rsquo; is really doing is just pulling the dependency&amp;rsquo;s JavaScript code. Adding this code to the in the in-line javascript will accomplish the same. Of course it won&amp;rsquo;t be pulling the latest version every time and will get messy pretty fast if the dependency has its own dependencies, but with &lt;a href="https://snyk.io/blog/snyk-200-malicious-npm-packages-cobalt-strike-dependency-confusion-attacks/">the recent supply-chain attacks&lt;/a> this might even be a good idea!&lt;/p>
&lt;h1 id="get-sha-256-action">
Get SHA-256 action
&lt;a class="heading-link" href="#get-sha-256-action">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>The code shared in the StackOverflow question depends on the crypto-js library, its HmacSHA256 method. To address my needs, I use the SHA256 method instead, which is available &lt;a href="https://raw.githubusercontent.com/crypto-js/crypto-js/refs/heads/latest/dist/sha256.js">here&lt;/a>. With this in place, the SHA256 method works, with in-line javascript, no need for function actions or function apps.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/javascript-reuse-action.png" alt="alt text">&lt;/p>
&lt;h1 id="reuse-the-crypo-js-dependency-code">
Reuse the crypo-js dependency code
&lt;a class="heading-link" href="#reuse-the-crypo-js-dependency-code">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>The solution above addresses the need of the StackOverflow question and works for my needs as well, however in my case I need to get those hashes in more than one workflow in my Logic App. Duplicating 4.5Kb of Javascript on every one of these actions is not something I&amp;rsquo;m comfortable with.&lt;/p>
&lt;p>To reuse this code, I ended up placing it as a parameter. Parameters in Logic Apps Standard are maintained in a JSON file, the only &lt;a href="https://learn.microsoft.com/en-us/azure/logic-apps/logic-apps-limits-and-config?tabs=consumption#workflow-definition-limits">documented limit&lt;/a> is about their number, not their size, and its value is available to all workflows.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/javascript-reuse-parameter.png" alt="alt text">&lt;/p>
&lt;p>Now I can have this action as many times as needed in my Logic App, without duplicating the code of the dependency.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">eval(workflowContext.actions.Set_Crypto_Library.outputs);
&lt;span style="font-weight:bold">const&lt;/span> hash = CryptoJS.SHA256(JSON.stringify(workflowContext.actions.Parse_Input.outputs));
&lt;span style="font-weight:bold">return&lt;/span> hash.toString();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The Set Crypto Library action is a compose action to make the text of the parameter available to the in-line javascript action.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="font-weight:bold">&amp;#34;type&amp;#34;&lt;/span>: &lt;span style="font-style:italic">&amp;#34;Compose&amp;#34;&lt;/span>,
&lt;span style="font-weight:bold">&amp;#34;inputs&amp;#34;&lt;/span>: &lt;span style="font-style:italic">&amp;#34;@parameters(&amp;#39;cryptojs&amp;#39;)&amp;#34;&lt;/span>,
&lt;span style="font-weight:bold">&amp;#34;runAfter&amp;#34;&lt;/span>: {
&lt;span style="font-weight:bold">&amp;#34;Parse_Input&amp;#34;&lt;/span>: [
&lt;span style="font-style:italic">&amp;#34;SUCCEEDED&amp;#34;&lt;/span>
]
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Is this a recommended approach?, for simple scenarios like this one, maybe. As I mentioned at the beginning, the main reason for this post is not about promoting this solution as a recommended way to do this but to show there are ways to work around technology limitations. As long as the developer is aware of the tradeoffs and communicates the potential pitfalls of the work around, he or she will have more options than just saying &amp;ldquo;we can only use&amp;hellip;&amp;rdquo;, as in the StackOverflow answer.&lt;/p></description></item><item><title>Failing failed bash Azure DevOps tasks</title><link>https://davidtriana.com/posts/2024/failing-failed-bash/</link><pubDate>Fri, 13 Sep 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/failing-failed-bash/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Automating infrastructure as code or continuous delivery with AzDevOps pipelines sometimes requires bash scripts when Arm/Bicep or the built-in tasks fell short. Bash scripts work great, however one issue that surprised me in a production release a few weeks ago is the fact that the failure of one of the commands in the script is not enough to mark the task as failed. For example, this YAML pipeline:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="font-weight:bold">trigger&lt;/span>:
- none
&lt;span style="font-weight:bold">pool&lt;/span>:
&lt;span style="font-weight:bold">vmImage&lt;/span>: ubuntu-latest
&lt;span style="font-weight:bold">steps&lt;/span>:
- &lt;span style="font-weight:bold">task&lt;/span>: AzureCLI@2
&lt;span style="font-weight:bold">displayName&lt;/span>: Get Application Insights Connection String
&lt;span style="font-weight:bold">inputs&lt;/span>:
&lt;span style="font-weight:bold">azureSubscription&lt;/span>: &lt;span style="font-style:italic">&amp;#39;MSDN Sub&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">scriptType&lt;/span>: &lt;span style="font-style:italic">&amp;#39;bash&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">scriptLocation&lt;/span>: &lt;span style="font-style:italic">&amp;#39;inlineScript&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">inlineScript&lt;/span>: |&lt;span style="font-style:italic">
&lt;/span>&lt;span style="font-style:italic"> MSYS_NO_PATHCONV=1
&lt;/span>&lt;span style="font-style:italic"> connString=$(az monitor app-insights component show -a appi-titan-prod -g rg-skynet-prod --query &amp;#39;connectionString&amp;#39; -o tsv)
&lt;/span>&lt;span style="font-style:italic"> echo &amp;#34;##vso[task.setvariable variable=connString;isoutput=true;isreadonly=true;]$connString&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Intended to set a pipeline variable, when ran is marked as success:&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/devops_success.png" alt="AzDevOps Success Job Run">&lt;/p>
&lt;p>despite the fact that the resource group wasn&amp;rsquo;t present:&lt;/p>
&lt;p>From the run logs:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-text" data-lang="text">ERROR: (ResourceGroupNotFound) Resource group &amp;#39;rg-skynet-prod&amp;#39; could not be found.
Code: ResourceGroupNotFound
Message: Resource group &amp;#39;rg-skynet-prod&amp;#39; could not be found.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But because the last command, echo, succeeds, the exit code of the task is 0, causing AzDevOps to mark the task as success.&lt;/p>
&lt;h2 id="making-the-task-fail">
Making the task fail
&lt;a class="heading-link" href="#making-the-task-fail">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>After trying everything I found in the web, the solution is to add the&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">set -e
&lt;/code>&lt;/pre>&lt;/div>&lt;p>command at the beginning of the script. From &lt;a href="https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html#index-set">the documentation&lt;/a>, this command instructs the system to exit immediately if a command fails.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/devops_failed.png" alt="AzDevOps failed job run">&lt;/p>
&lt;p>Other solutions make reference to the&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="font-weight:bold">failOnStderr&lt;/span>: &lt;span style="font-weight:bold">true&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>task input parameter. This parameter on its own didn&amp;rsquo;t work for me, at least when dealing with AZ CLI commands.&lt;/p>
&lt;p>Finally, the&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="font-weight:bold">continueOnError&lt;/span>: &lt;span style="font-weight:bold">false&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>task parameter seems to be the default behavior and doesn&amp;rsquo;t need to be added.&lt;/p></description></item><item><title>Logic App VNET Integration Fails with ERROR: There was a conflict. SiteConfig.VnetRouteAllEnabled cannot be modified. Please modify the Site.VnetRouteAllEnabled property</title><link>https://davidtriana.com/posts/2024/logic-app-vnet-integration-error/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/logic-app-vnet-integration-error/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Something changed in Azure in the last week of April 2024. Specifically, one infrastructure as code pipeline that has been working fine for months started failing April 30. More specifically, this pipeline deploys a Logic App Standard Application, then setups VNET Integration for the logic app to be able to call internal and on-premises services.&lt;/p>
&lt;p>The command&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">az webapp vnet-integration add --resource-group &lt;span style="font-weight:bold;font-style:italic">\
&lt;/span>&lt;span style="font-weight:bold;font-style:italic">&lt;/span> --name &lt;span style="font-weight:bold">$(&lt;/span>logicAppName&lt;span style="font-weight:bold">)&lt;/span> &lt;span style="font-weight:bold;font-style:italic">\
&lt;/span>&lt;span style="font-weight:bold;font-style:italic">&lt;/span> --vnet &lt;span style="font-weight:bold">$(&lt;/span>vnetResourceId&lt;span style="font-weight:bold">)&lt;/span> &lt;span style="font-weight:bold;font-style:italic">\
&lt;/span>&lt;span style="font-weight:bold;font-style:italic">&lt;/span> --subnet &lt;span style="font-weight:bold">$(&lt;/span>subnetName&lt;span style="font-weight:bold">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Fails with the error message&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">ERROR: There was a conflict. SiteConfig.VnetRouteAllEnabled cannot be modified. Please modify the Site.VnetRouteAllEnabled property
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="workaround">
Workaround
&lt;a class="heading-link" href="#workaround">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>Not really sure what happened or what changed. This pipeline is reused among many logic apps in different subscriptions and still works for some of the existing logic apps.&lt;/p>
&lt;p>Searching for the error message, I was surprised by Bing Chat understanding the problem and suggesting a solution that worked!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">az resource update --resource-group &amp;lt;group-name&amp;gt; --name &amp;lt;app-name&amp;gt; --resource-type &lt;span style="font-style:italic">&amp;#34;Microsoft.Web/sites&amp;#34;&lt;/span> --set properties.vnetRouteAllEnabled=[true|false]
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Used that command with true as the value and now my pipeline is back in business.&lt;/p></description></item><item><title>Continuous delivery for Azure Workbooks using Azure DevOps</title><link>https://davidtriana.com/posts/2024/cd-workbooks/</link><pubDate>Sun, 28 Apr 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/cd-workbooks/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Azure Workbooks are great!, with an easy to use graphical designer to put together interactive queries and reports, no need to code, and available directly in the portal, no need to host a new application.&lt;/p>
&lt;p>I have been using Azure Workbooks for the last couple of months to show summaries and details on failures for several business applications, some running as Logic Apps Standard, some as Azure Container Apps.&lt;/p>
&lt;p>In this blog post I share the way I automate the deployment of these Workbooks, following patterns similar to the ones used in continuous deployment for regular applications. Here the workflow is not really an application in the sense of the need to pull dependencies, build and deploy, but by following these patterns, the need for inspection, approvals and reuse between environments is satisfied.&lt;/p>
&lt;h2 id="creating-log-entries-to-populate-the-workbook">
Creating log entries to populate the workbook
&lt;a class="heading-link" href="#creating-log-entries-to-populate-the-workbook">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>This section is only to address the need of data to show in the workflow. Real applications are probably already creating all these logs. The code bellow is a simple console application, starting from &lt;a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/ilogger?tabs=dotnet6#console-application">Microsoft&amp;rsquo;s sample code&lt;/a>, I added console output to be able to check the outcome live while running. The program creates logs entries simulating a process that runs every 5 seconds, doing 5 tasks every time, simulating some tasks taking longer and failures every once in a while.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">System.Diagnostics&lt;/span>;
&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">Microsoft.ApplicationInsights.Channel&lt;/span>;
&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">Microsoft.ApplicationInsights.Extensibility&lt;/span>;
&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">Microsoft.Extensions.DependencyInjection&lt;/span>;
&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">Microsoft.Extensions.Logging&lt;/span>;
&lt;span style="font-weight:bold">using&lt;/span> &lt;span style="font-weight:bold">var&lt;/span> channel = &lt;span style="font-weight:bold">new&lt;/span> InMemoryChannel();
&lt;span style="font-weight:bold">try&lt;/span>
{
IServiceCollection services = &lt;span style="font-weight:bold">new&lt;/span> ServiceCollection();
services.Configure&amp;lt;TelemetryConfiguration&amp;gt;(config =&amp;gt; config.TelemetryChannel = channel);
services.AddLogging(builder =&amp;gt;
{
&lt;span style="font-style:italic">// Only Application Insights is registered as a logger provider
&lt;/span>&lt;span style="font-style:italic">&lt;/span> builder.AddApplicationInsights(
configureTelemetryConfiguration: (config) =&amp;gt; config.ConnectionString = &lt;span style="font-style:italic">&amp;#34;---the connection string---&amp;#34;&lt;/span>,
configureApplicationInsightsLoggerOptions: (options) =&amp;gt; { }
);
builder.AddJsonConsole(options =&amp;gt;
{
options.IncludeScopes = &lt;span style="font-weight:bold">true&lt;/span>;
options.TimestampFormat = &lt;span style="font-style:italic">&amp;#34;HH:mm:ss &amp;#34;&lt;/span>;
});
});
&lt;span style="">var&lt;/span> serviceProvider = services.BuildServiceProvider();
&lt;span style="">var&lt;/span> logger = serviceProvider.GetRequiredService&amp;lt;ILogger&amp;lt;Program&amp;gt;&amp;gt;();
&lt;span style="">var&lt;/span> cancellationTokenSource = &lt;span style="font-weight:bold">new&lt;/span> CancellationTokenSource();
&lt;span style="font-weight:bold">await&lt;/span> MainLoop(cancellationTokenSource.Token,
logger, 5000).ConfigureAwait(&lt;span style="font-weight:bold">false&lt;/span>);
logger.LogInformation(&lt;span style="font-style:italic">&amp;#34;Logger is working...&amp;#34;&lt;/span>);
}
&lt;span style="font-weight:bold">finally&lt;/span>
{
&lt;span style="font-style:italic">// Explicitly call Flush() followed by Delay, as required in console apps.
&lt;/span>&lt;span style="font-style:italic">&lt;/span> &lt;span style="font-style:italic">// This ensures that even if the application terminates, telemetry is sent to the back end.
&lt;/span>&lt;span style="font-style:italic">&lt;/span> channel.Flush();
&lt;span style="font-weight:bold">await&lt;/span> Task.Delay(TimeSpan.FromMilliseconds(1000));
}
&lt;span style="font-weight:bold">return&lt;/span>;
&lt;span style="font-weight:bold">static&lt;/span> &lt;span style="font-weight:bold">async&lt;/span> Task MainLoop(
CancellationToken cancellationToken,
ILogger&amp;lt;Program&amp;gt; logger,
&lt;span style="">int&lt;/span> frequencyInMilliSeconds)
{
&lt;span style="">var&lt;/span> totalRuns=0;
&lt;span style="font-weight:bold">while&lt;/span> (!cancellationToken.IsCancellationRequested &amp;amp;&amp;amp; totalRuns &amp;lt; 200)
{
&lt;span style="font-style:italic">// Create a child task that runs in parallel
&lt;/span>&lt;span style="font-style:italic">&lt;/span> &lt;span style="">var&lt;/span> childTask = Task.Run(&lt;span style="font-weight:bold">async&lt;/span> () =&amp;gt;
{
&lt;span style="">var&lt;/span> transactionId = DateTime.UtcNow.ToString(&lt;span style="font-style:italic">&amp;#34;yyyyMMddHHmmssfff&amp;#34;&lt;/span>);
&lt;span style="font-weight:bold">using&lt;/span> (logger.BeginScope(&lt;span style="font-style:italic">&amp;#34;{transactionId}&amp;#34;&lt;/span>, transactionId))
{
&lt;span style="">var&lt;/span> totalTimeTaken = &lt;span style="font-weight:bold">new&lt;/span> Stopwatch();
totalTimeTaken.Start();
logger.LogInformation(
&lt;span style="font-style:italic">&amp;#34;Pest finder {eventTypeName}&amp;#34;&lt;/span>,
&lt;span style="font-style:italic">&amp;#34;started&amp;#34;&lt;/span>);
&lt;span style="font-weight:bold">try&lt;/span>
{
&lt;span style="">var&lt;/span> stopWatch = &lt;span style="font-weight:bold">new&lt;/span> Stopwatch();
&lt;span style="font-weight:bold">for&lt;/span> (&lt;span style="">var&lt;/span> i = 1; i &amp;lt; 6; i++)
{
stopWatch.Restart();
&lt;span style="font-weight:bold">await&lt;/span> Task.Delay(RandomNumber(1000, 20000), cancellationToken);
&lt;span style="font-weight:bold">if&lt;/span> (RandomNumber(0, 100) &amp;gt; 90) &lt;span style="font-weight:bold">throw&lt;/span> &lt;span style="font-weight:bold">new&lt;/span> Exception(&lt;span style="font-style:italic">&amp;#34;Pest finder overrun!&amp;#34;&lt;/span>);
logger.LogInformation(
&lt;span style="font-style:italic">&amp;#34;Pest finder task {taskNumber} took {timeTaken}ms&amp;#34;&lt;/span>,
i,
stopWatch.ElapsedMilliseconds);
}
logger.LogInformation(
&lt;span style="font-style:italic">&amp;#34;Pest finder {eventTypeName} and took {totalTimeTaken}ms&amp;#34;&lt;/span>,
&lt;span style="font-style:italic">&amp;#34;completed&amp;#34;&lt;/span>, totalTimeTaken.ElapsedMilliseconds);
}
&lt;span style="font-weight:bold">catch&lt;/span> (Exception ex)
{
logger.LogError(ex,
&lt;span style="font-style:italic">&amp;#34;Pest finder {eventTypeName} with error {errorMessage} and took {totalTimeTaken}ms&amp;#34;&lt;/span>,
&lt;span style="font-style:italic">&amp;#34;completed&amp;#34;&lt;/span>, ex.Message, totalTimeTaken.ElapsedMilliseconds);
}
}
});
&lt;span style="font-weight:bold">await&lt;/span> Task.Delay(frequencyInMilliSeconds, cancellationToken).ConfigureAwait(&lt;span style="font-weight:bold">false&lt;/span>);
totalRuns++;
}
}
&lt;span style="font-weight:bold">static&lt;/span> &lt;span style="">int&lt;/span> RandomNumber(&lt;span style="">int&lt;/span> min, &lt;span style="">int&lt;/span> max)
{
&lt;span style="">var&lt;/span> random = &lt;span style="font-weight:bold">new&lt;/span> Random();
&lt;span style="font-weight:bold">return&lt;/span> random.Next(min, max);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="creating-the-workbook">
Creating the workbook
&lt;a class="heading-link" href="#creating-the-workbook">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>Now that we have some logs in place, its time to create the workbook. In the Azure Portal, find the application insights instance which was receiving these logs, then navigate to workbooks&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-navigate.png" alt="Navigate to workbooks link">&lt;/p>
&lt;p>The workbooks screen offers two templates, select the default template&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-select-default-template.png" alt="Template options">&lt;/p>
&lt;p>Workbooks are composed of blocks, added vertically one after the other. The default template adds two blocks, one text block and one query block&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-initial-template.png" alt="Default template">&lt;/p>
&lt;p>I updated the query in the query block according to the logs I created&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">union * | where customDimensions.eventTypeName == &amp;#39;completed&amp;#39; | summarize count() by bin(timestamp, 1m), itemType
| render barchart
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-first-query.png" alt="First query">&lt;/p>
&lt;p>And this already shows the value of workbooks!, the ability to produce very nice reports and summaries from logs, without code and without deploying an additional application. This first query shows a summary.&lt;/p>
&lt;p>I used the +Add option to add a new query block&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-add-query.png" alt="add query">&lt;/p>
&lt;p>and in this next query I&amp;rsquo;m getting the details of all the processes that failed&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">exceptions | project timestamp, TransactionId = customDimensions.transactionId, Error = customDimensions.errorMessage
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To add some interactivity I configured the &amp;ldquo;export parameter&amp;rdquo; feature so that when a row from the results is selected, the selected value is made available as a parameter for the next query&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-second-query-add-parameter.png" alt="Adding parameters">&lt;/p>
&lt;p>Next I added the last query, to show all the log entries for that process run&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">union traces,exceptions | where customDimensions.transactionId == {txid}
| order by timestamp asc
| project timestamp, message = iif(itemType==&amp;#39;trace&amp;#39;, message, customDimensions.FormattedMessage), timetaken = customDimensions.timeTaken
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The final result looks like this&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-end-result.png" alt="Final result">&lt;/p>
&lt;p>Workbooks also allow &amp;ldquo;link&amp;rdquo; columns, with the ability to directly open Azure Portal blades or invoke actions, as shown &lt;a href="https://techcommunity.microsoft.com/t5/azure-integration-services-blog/extending-logic-apps-app-insight-integration-with-azure/ba-p/3784062">here&lt;/a> for Logic Apps Standard where the workbook includes links to the run details and to the &amp;ldquo;resubmit&amp;rdquo; action for the workflow.&lt;/p>
&lt;h2 id="creating-the-pipeline">
Creating the pipeline
&lt;a class="heading-link" href="#creating-the-pipeline">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>The workbook is now in place and working, this however was done directly in the Azure Portal, manually, something that I don&amp;rsquo;t want to repeat for my TEST, STAGING, PERF or PRODUCTION environments. Just like with code, ideally, this needs to be version managed and go though deployment pipelines that parameterize by environment when needed, and control the approvals process to promote from lower to higher environments.&lt;/p>
&lt;p>The workbooks user interface in the portal already provides some help for this by producing the ARM template needed to deploy the workbook via the Azure CLI. To obtain the ARM template, in the workbook editor view select the advanced editor&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-advanced-editor-button.png" alt="Advanced editor">&lt;/p>
&lt;p>Then use the ARM template from the options offered by the Azure Portal&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/workbooks-export-options.png" alt="Export options">&lt;/p>
&lt;p>This option works, however the content of the workbook is all in one single place, the serializedData property, which makes it harder to inspect when thinking about code reviews and pull requests. The option I use is the first one, the &amp;ldquo;Gallery template&amp;rdquo; option, which provides the full content of the workbook in an easy to read and inspect JSON format.&lt;/p>
&lt;p>To use this option I save this content as a JSON file, which I then add to source control, then pull during deployment using the loadTextContent bicep function.&lt;/p>
&lt;p>Assuming separate subscriptions per environment, my bicep template looks like this, and a critical piece is the uniqueness of the name of the workflow. This name needs to be unique, and the same between pipeline runs to ensure the workbook is updated instead of adding a new workbook. The GUID function accepts as many parameters as needed so depending on the project I might need to add more parameters to make it unique.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">@description(&amp;#39;The datacenter to use for the deployment.&amp;#39;)
param location string = resourceGroup().location
param environmentName string
param environmentShortNameUpperCase string = toUpper(environmentName)
param workbookSourceId string = &amp;#39;/subscriptions/${subscription().subscriptionId}/resourceGroups/${resourceGroup().name}/providers/microsoft.insights/components/appinsights-${environmentName}&amp;#39;
resource existing_application_insights &amp;#39;Microsoft.Insights/components@2020-02-02&amp;#39; existing = {
name: &amp;#39;appinsights-${environmentName}&amp;#39;
scope: resourceGroup()
}
resource ProcessRunsSummaryWorkbook &amp;#39;Microsoft.Insights/workbooks@2023-06-01&amp;#39; = {
name: guid(subscription().id, resourceGroup().id, existing_application_insights.id)
location: location
tags: {
costCenter: &amp;#39;Demos&amp;#39;
project: &amp;#39;Demos&amp;#39;
}
kind: &amp;#39;shared&amp;#39;
properties: {
category: &amp;#39;workbook&amp;#39;
displayName: &amp;#39;Pest control runs - ${environmentShortNameUpperCase}&amp;#39;
serializedData: loadTextContent(&amp;#39;PestControlWorkbook.json&amp;#39;)
sourceId: workbookSourceId
version: &amp;#39;1.0&amp;#39;
}
dependsOn: [
existing_application_insights
]
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To deploy this bicep template I use the Azure Devops deployment task&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">- &lt;span style="font-weight:bold">task&lt;/span>: AzureResourceManagerTemplateDeployment@3
&lt;span style="font-weight:bold">displayName&lt;/span>: &lt;span style="font-style:italic">&amp;#39;Deploy Workbook&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">inputs&lt;/span>:
&lt;span style="font-weight:bold">azureResourceManagerConnection&lt;/span>: ${{ parameters.serviceConnection }}
&lt;span style="font-weight:bold">subscriptionId&lt;/span>: &lt;span style="font-style:italic">&amp;#39;$(subscriptionId)&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">action&lt;/span>: &lt;span style="font-style:italic">&amp;#39;Create Or Update Resource Group&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">resourceGroupName&lt;/span>: $(resourceGroupName)
&lt;span style="font-weight:bold">location&lt;/span>: $(resourceGroupLocation)
&lt;span style="font-weight:bold">csmFile&lt;/span>: &lt;span style="font-style:italic">&amp;#39;$(Pipeline.Workspace)/$(artifactName)/template-workbooks.bicep&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">overrideParameters&lt;/span>: &amp;gt;-&lt;span style="font-style:italic">
&lt;/span>&lt;span style="font-style:italic"> &lt;/span> -environmentName $(environmentShortName)
&lt;span style="font-weight:bold">deploymentMode&lt;/span>: &lt;span style="font-style:italic">&amp;#39;Incremental&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Which is called by a multistage pipeline that takes care of each of the environments, and where a typical stage looks like this&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">- &lt;span style="font-weight:bold">stage&lt;/span>: STAGING
&lt;span style="font-weight:bold">displayName&lt;/span>: &lt;span style="font-style:italic">&amp;#39;STAGING Deployment&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">variables&lt;/span>:
- &lt;span style="font-weight:bold">template&lt;/span>: pipeline-variables.yml
&lt;span style="font-weight:bold">parameters&lt;/span>:
&lt;span style="font-weight:bold">environmentShortName&lt;/span>: &lt;span style="font-style:italic">&amp;#39;stg&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">subscriptionId&lt;/span>: &lt;span style="font-style:italic">&amp;#39;---my guid---&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">jobs&lt;/span>:
- &lt;span style="font-weight:bold">template&lt;/span>: templates/iac-template.yml
&lt;span style="font-weight:bold">parameters&lt;/span>:
&lt;span style="font-weight:bold">azDevOpsEnvironment&lt;/span>: &lt;span style="font-style:italic">&amp;#39;Pest Control Staging&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">serviceConnection&lt;/span>: &lt;span style="font-style:italic">&amp;#39;azure-staging-service-connection&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>A complete example of multistage pipelines for infrastructure as code (IaC) and continuous integration (CI) and continuous delivery (CD) can be found in the &lt;a href="https://github.com/Azure/logicapps/tree/master/azure-devops-sample/.pipelines/classic">Microsoft guidance for DevOps with Azure Standard Logic Apps&lt;/a>&lt;/p></description></item><item><title>Dynamic Loops In Azure DevOps Pipelines</title><link>https://davidtriana.com/posts/2024/azdevops.loops/</link><pubDate>Fri, 26 Jan 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/azdevops.loops/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Being used to programming, loops feel very basic, like, for each one of these, do that. However, doing this in AzDevOps pipelines turned out to be not as easy.&lt;/p>
&lt;p>It is trivial, for a previously know set, like an array of environments [&amp;lsquo;dev,&amp;lsquo;qa&amp;rsquo;,&amp;lsquo;prod&amp;rsquo;], no problem there, but what if the set is determined dynamically, while the pipeline is running?&lt;/p>
&lt;p>This is exactly my need. I have a container app, publicly exposed to the internet, with a set of IP rules so that it can only be called by a Logic App. The thing is, the outgoing IP of the Logic App is not a single one and can change from deployment to deployment, so I need to obtain the list of IPs, then run a loop on those IP, to add them as rules.&lt;/p>
&lt;p>Of course I can deploy both the container app and the logic app in a VNET to avoid the need of these rules, not there yet unfortunately, other requirements and limitations make it necessary to keep these public.&lt;/p>
&lt;p>So why is not as easy?&lt;/p>
&lt;p>The Azure Devops loop support relies on the each keyword explained &lt;a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/process/expressions?view=azure-devops#each-keyword">here&lt;/a>,&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="font-weight:bold">parameters&lt;/span>:
- &lt;span style="font-weight:bold">name&lt;/span>: listOfStrings
&lt;span style="font-weight:bold">type&lt;/span>: object
&lt;span style="font-weight:bold">default&lt;/span>:
- one
- two
&lt;span style="font-weight:bold">steps&lt;/span>:
- ${{ each value in parameters.listOfStrings }}:
- &lt;span style="font-weight:bold">script&lt;/span>: echo ${{ value }}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, the &lt;code>${{ }}&lt;/code> syntax is not for runtime. Those expressions are expanded before running the workflow as explained &lt;a href="https://stackoverflow.com/a/75832425">here&lt;/a>,&lt;/p>
&lt;h1 id="using-bash-inside-the-task-to-run-the-loop">
Using bash inside the task to run the loop
&lt;a class="heading-link" href="#using-bash-inside-the-task-to-run-the-loop">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>The way I worked around this is by using bash loops, and the same can be accomplished with PowerShell,&lt;/p>
&lt;p>My code:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">- &lt;span style="font-weight:bold">task&lt;/span>: AzureCLI@2
&lt;span style="font-weight:bold">displayName&lt;/span>: Add Ip Security Allow Logic Apps
&lt;span style="font-weight:bold">name&lt;/span>: AddIpSecurityRestrictionsAllowLAs
&lt;span style="font-weight:bold">inputs&lt;/span>:
&lt;span style="font-weight:bold">azureSubscription&lt;/span>: myServiceConnectionName
&lt;span style="font-weight:bold">scriptType&lt;/span>: &lt;span style="font-style:italic">&amp;#39;bash&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">scriptLocation&lt;/span>: &lt;span style="font-style:italic">&amp;#39;inlineScript&amp;#39;&lt;/span>
&lt;span style="font-weight:bold">inlineScript&lt;/span>: |&lt;span style="font-style:italic">
&lt;/span>&lt;span style="font-style:italic"> MSYS_NO_PATHCONV=1
&lt;/span>&lt;span style="font-style:italic"> echo &amp;#34;Full Ip List is $(GetLogicAppsOutgoingIps.logicApps_outgoing)&amp;#34;
&lt;/span>&lt;span style="font-style:italic"> IFS=&amp;#39;,&amp;#39; read -ra la_ips &amp;lt;&amp;lt;&amp;lt; &amp;#34;$(GetLogicAppsOutgoingIps.logicApps_outgoing)&amp;#34;
&lt;/span>&lt;span style="font-style:italic"> for i in &amp;#34;${la_ips[@]}&amp;#34;;
&lt;/span>&lt;span style="font-style:italic"> do
&lt;/span>&lt;span style="font-style:italic"> DATE=$(date &amp;#39;+%Y%m%d%H%M%S&amp;#39;)
&lt;/span>&lt;span style="font-style:italic"> echo &amp;#34;Adding rule for $i&amp;#34;
&lt;/span>&lt;span style="font-style:italic"> az containerapp ingress access-restriction set \
&lt;/span>&lt;span style="font-style:italic"> --name theNameOfMyContainerApp \
&lt;/span>&lt;span style="font-style:italic"> --resource-group theNameOfTheResourceGroup \
&lt;/span>&lt;span style="font-style:italic"> --rule-name &amp;#34;Allow My Logic App $DATE&amp;#34; \
&lt;/span>&lt;span style="font-style:italic"> --ip-address &amp;#34;$i/32&amp;#34; \
&lt;/span>&lt;span style="font-style:italic"> --action Allow
&lt;/span>&lt;span style="font-style:italic"> done&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I&amp;rsquo;m adding the date to make the name unique, and the syntax to split the string and the loop in bash is explained &lt;a href="https://stackoverflow.com/a/918931">here&lt;/a>.&lt;/p>
&lt;p>The &lt;code>GetLogicAppsOutgoingIps.logicApps_outgoing&lt;/code> variable is set by a template that runs another AzureCLI bash script, that queries the outgoing IPs, and creates an array with that information,&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">logicAppIps=&lt;span style="font-weight:bold">$(&lt;/span> az logicapp show -n theLogicAppName -g theResourceGroupName --query &lt;span style="font-style:italic">&amp;#39;outboundIpAddresses&amp;#39;&lt;/span> -o tsv&lt;span style="font-weight:bold">)&lt;/span>
&lt;span style="font-weight:bold">if&lt;/span> [[ $logicAppIps == &lt;span style="font-style:italic">&amp;#34;&amp;#34;&lt;/span> ]]; &lt;span style="font-weight:bold">then&lt;/span>
exit 1
&lt;span style="font-weight:bold">fi&lt;/span>
echo &lt;span style="font-style:italic">&amp;#34;##vso[task.setvariable variable=logicApps_outgoing;isoutput=true;isreadonly=true;]&lt;/span>$logicAppIps&lt;span style="font-style:italic">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And there it is!, a dynamic loop in an Azure Devops pipeline.&lt;/p></description></item><item><title>Logic Apps Standard DB2 Query and Parameters</title><link>https://davidtriana.com/posts/2024/db2-queries/</link><pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2024/db2-queries/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>In Logic Apps Standard we now have this in-app DB2 actions, no need for managed connections, just make DB2 calls directly from the Logic App.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/add_db2_actions.png" alt="DB2 Shapes">&lt;/p>
&lt;p>While using these shapes, the execute query in particular, it took me a while to figure out how to set the parameter for the query.&lt;/p>
&lt;h1 id="adjusting-the-query-and-parameter">
Adjusting the query and parameter
&lt;a class="heading-link" href="#adjusting-the-query-and-parameter">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>The way it worked for me is using the ? sign for the parameter, and a numeric index for the parameter definition.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2024/db2_query.png" alt="DB2 Query">&lt;/p>
&lt;p>This was after trying named parameters, the @ sign, and reading the links on the first two pages of Bing results for this question without any luck. This solution worked for me, however it might be different for you depending on the underlying database and its configuration, in my case this is against an Informix 14 database.&lt;/p></description></item><item><title>Logging HTTP Requests in .NET Core API</title><link>https://davidtriana.com/posts/2023/logging-http-requests/</link><pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2023/logging-http-requests/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Troubleshooting Web APIs, especially when released to the world, often require the submitted payload, to be able to reproduce the issue. HTTP payloads are not captured by logging be default, and it should be that way to avoid introducing performance and privacy issues, however, when needed, there are many ways to do it.&lt;/p>
&lt;p>Some teams will explicitly add code to log the request, for each of the requests where the payload is needed. This is good, but adds a lot of code to maintain, at least one line per API method.&lt;/p>
&lt;p>Other teams will create a generic logging mechanism, introduced in runtime via a wrapper on each call or any of the middleware interceptors available in .NET. This is good since it can be maintained in a single place, remains custom, additional code.&lt;/p>
&lt;p>My team, looking for ways to add as little code as possible, rely on the build it HttpLogging service. Not customizable as with custom code, but its build need, no need for custom logging code for it to work.&lt;/p>
&lt;h1 id="adding-httplogging">
Adding HTTPLogging
&lt;a class="heading-link" href="#adding-httplogging">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>To add HTTPLogging to a .NET 7 Core APIs project:&lt;/p>
&lt;ol>
&lt;li>In program.cs inside the static main method, when declaring the services but before creating the app&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback"> builder.Services.AddHttpLogging(logging =&amp;gt;
{
logging.LoggingFields = HttpLoggingFields.RequestBody;
logging.RequestBodyLogLimit = 1024;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The LoggingFields properties is a flags property, other fields can be added, here I&amp;rsquo;m only interested in the request body, other characteristics of the request like the URL and Method are being captured already by the request type logs. The Limit property, which is in bytes, is to prevent polluting the log with very long payloads, either accidental, malicious, or real with endpoints where users submit images.&lt;/p>
&lt;ol>
&lt;li>In program.cs inside the static main method, after creating the app&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">app.UseWhen(
context =&amp;gt; !(
context.Request.Path.StartsWithSegments(&amp;#34;/api/user/login&amp;#34;) ||
context.Request.Path.StartsWithSegments(&amp;#34;/api/user/password&amp;#34;)),
builder =&amp;gt; builder.UseHttpLogging());
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here I use the UseWhen filter, to prevent logging passwords. In general, logging secrets or any kind of confidential information should be prevented. More complex APIs might require much more sophisticated mechanisms to avoid privacy incidents while keeping the ability to troubleshoot problematic HTTP requests.&lt;/p>
&lt;ol>
&lt;li>In appsettings.json, in the Logging section, add the relevant lines for &lt;code>Microsoft.AspNetCore.HttpLogging.HttpLoggingMiddleware&lt;/code> based on&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback"> &amp;#34;Logging&amp;#34;: {
&amp;#34;LogLevel&amp;#34;: {
&amp;#34;Default&amp;#34;: &amp;#34;Information&amp;#34;,
&amp;#34;Microsoft.AspNetCore.HttpLogging.HttpLoggingMiddleware&amp;#34;: &amp;#34;Information&amp;#34;,
&amp;#34;Microsoft.AspNetCore&amp;#34;: &amp;#34;Warning&amp;#34;,
&amp;#34;Microsoft&amp;#34;: &amp;#34;Warning&amp;#34;,
&amp;#34;Microsoft.Hosting.Lifetime&amp;#34;: &amp;#34;Information&amp;#34;
},
&amp;#34;ApplicationInsights&amp;#34;: {
&amp;#34;LogLevel&amp;#34;: {
&amp;#34;Default&amp;#34;: &amp;#34;Warning&amp;#34;,
&amp;#34;Microsoft.AspNetCore.HttpLogging.HttpLoggingMiddleware&amp;#34;: &amp;#34;Information&amp;#34;
}
}
},
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The ApplicationInsights section is only needed if that&amp;rsquo;s where you want your logs to go to.&lt;/p>
&lt;h1 id="finding-the-logs-in-application-insights">
Finding the logs in Application Insights
&lt;a class="heading-link" href="#finding-the-logs-in-application-insights">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Running in Visual Studio or looking at the logs stream in Azure App Services will show the entries. In Application Insights the logs will be of type Trace, severity information, and the message starts with RequestBody, for example&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Local Time&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Details&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>9:41:40.179 AM&lt;/td>
&lt;td>Trace&lt;/td>
&lt;td>&lt;strong>Severity level:&lt;/strong> Information, &lt;strong>Message:&lt;/strong> RequestBody: {&amp;ldquo;productId&amp;rdquo;:&amp;ldquo;INFANTRYALPHA2023&amp;rdquo;,&amp;ldquo;quantity&amp;rdquo;:3}&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Listing Azure Function Apps Framework Version</title><link>https://davidtriana.com/posts/2022/listing-azure-functionapps-framework/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2022/listing-azure-functionapps-framework/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Azure Function Apps running with .NET 3.1 will go out of support on Dec 3 2022, something that the Azure Portal reminds users every time they visit their outdated functions. If like me, you have several functions, whouldn&amp;rsquo;t it be nice to be able to get a list of all the functions that should be updated?&lt;/p>
&lt;h1 id="solution">
Solution
&lt;a class="heading-link" href="#solution">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>A simple &lt;code>az functionapps list&lt;/code> should do the trick, however the properties that provide this information are in one of the objects, siteConfig, which is not populated by the &lt;code>list&lt;/code> command, and after searching for a while I found &lt;a href="https://github.com/Azure/azure-cli/issues/21548#issuecomment-1061634921">this solution for WebApps&lt;/a>, the command for Function Apps is&lt;/p>
&lt;p>&lt;code>az functionapp list --query '[].id' -o tsv | xargs | xargs -I{} bash -c &amp;quot;az functionapp config show --ids {} --query '[].[name, resourceGroup,linuxFxVersion, netFrameworkVersion]' --out table&amp;quot;&lt;/code>&lt;/p>
&lt;p>This command will list all the functions in the current subscription, provided proper permissions.&lt;/p>
&lt;p>The output looks like this:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Column1&lt;/th>
&lt;th>Column2&lt;/th>
&lt;th>Column3&lt;/th>
&lt;th>Column4&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>tseries-urban-cars&lt;/td>
&lt;td>cars-classifier&lt;/td>
&lt;td>DOTNET|6.0&lt;/td>
&lt;td>v6.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tseries-urban-buildings&lt;/td>
&lt;td>buildings-location&lt;/td>
&lt;td>v4.0&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>tseries-urban-weapons&lt;/td>
&lt;td>weapons-catalog&lt;/td>
&lt;td>DOTNET|6.0&lt;/td>
&lt;td>v6.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>targets&lt;/td>
&lt;td>targets-catalog&lt;/td>
&lt;td>DOTNET|3.1&lt;/td>
&lt;td>v4.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Rows 1 and 3 were updated already, row 2 is not .NET, and the last needs to be updated&lt;/p></description></item><item><title>Renewing Microsoft Certifications</title><link>https://davidtriana.com/posts/2021/renewing-microsoft-certifications/</link><pubDate>Mon, 18 Oct 2021 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2021/renewing-microsoft-certifications/</guid><description>&lt;h1 id="action-required---your-microsoft-certification-will-expire-in-180-days">
Action required - Your Microsoft Certification will expire in 180 days!
&lt;a class="heading-link" href="#action-required---your-microsoft-certification-will-expire-in-180-days">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>That email subject, from May 21, asked for action, to get one of my certifications renewed, or &amp;ldquo;If your certification expires, you must earn the certification again by passing the required certification exam(s)&amp;rdquo;&lt;/p>
&lt;p>This renewal process is &lt;a href="https://docs.microsoft.com/en-us/learn/certifications/renew-your-microsoft-certification">new in many ways&lt;/a>, main differences are&lt;/p>
&lt;ul>
&lt;li>The topics covered are not necessarily the same as for the original exam/certification&lt;/li>
&lt;li>The exam itself is simpler than the proctored exam, no proctor, no dedicated exam app&lt;/li>
&lt;/ul>
&lt;p>I renewed 3 certifications with this process,&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/learn/certifications/azure-developer/renew/">Azure Developer Associate&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/learn/certifications/devops-engineer/renew/">DevOps Engineer Expert&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/learn/certifications/azure-solutions-architect/renew/">Azure Solutions Architect Expert&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I passed all on the first try, however the renewal exams can be repeated as many times as needed&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/exams.png" alt="&amp;ldquo;Exams&amp;rdquo;" title="Exams">&lt;/p>
&lt;p>To prepare, I went through all the linked materials on each of the certification pages, all of which go to the Microsoft Learn site, and include theory, labs and exam. I highly recommend this approach because&lt;/p>
&lt;ul>
&lt;li>The liked materials are directly related to the questions in the renewal exam&lt;/li>
&lt;li>The Microsoft Learn materials and labs are very well made, up to date and relevant&lt;/li>
&lt;/ul>
&lt;p>During the renewal exam, without a proctor or dedicated app, nothing prevents you from navigating back to the learning materials or searching for the answers online. While this approach might work to renew the certification, I think that misses the point. I think going through the materials preparing for the exam, and then consciously answering the exam questions fulfills the &amp;ldquo;brush up on your skills&amp;rdquo; objective in the invitation email.&lt;/p>
&lt;p>About the individual exams, what I found is that all the topics are covered in the learning materials and a lot of the topics from the original exams are not part of the renewal. The questions are less &amp;ldquo;tricky&amp;rdquo; than in the proctored exams and all the questions are multiple selections, no labs, no &amp;ldquo;order the commands&amp;rdquo; or any other of the question types available in the proctored exams.&lt;/p>
&lt;h1 id="see-more">
See More
&lt;a class="heading-link" href="#see-more">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Something that happened to me while preparing for the DevOps exam, opening the links to the learning materials, is that I missed some of the materials. While doing the exam I got some questions for which I wasn&amp;rsquo;t prepared, then after the exam I went back to the page and noticed the &amp;ldquo;See More&amp;rdquo; link at the bottom of the list of training materials, same link is present in the Architect Expert exam, and I learned my lesson.&lt;/p>
&lt;h1 id="celebrate">
Celebrate
&lt;a class="heading-link" href="#celebrate">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/celebrate.png" alt="&amp;ldquo;Celebrate&amp;rdquo;" title="Celebrate">&lt;/p></description></item><item><title>Deploying Log4Brains ADRs in Azure Static Sites</title><link>https://davidtriana.com/posts/2021/deploying-log4brains-adr-in-azure-static-sites/</link><pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2021/deploying-log4brains-adr-in-azure-static-sites/</guid><description>&lt;h1 id="scenario">
Scenario
&lt;a class="heading-link" href="#scenario">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Suppose your project has decided to use &lt;a href="https://github.com/thomvaill/log4brains">Log4Brains&lt;/a> to record architectural decisions and now you need to make the resulting website available, in Microsoft Azure, via a CD Pipeline. To learn about &lt;a href="https://en.wikipedia.org/wiki/Architectural_decision#Decision_documentation">ADRs&lt;/a> or architectural decision records I highly recommend &lt;a href="https://ardalis.com/getting-started-with-architecture-decision-records/">Steve Smith&amp;rsquo;s post about it&lt;/a>.&lt;/p>
&lt;h2 id="install-log4brains-and-create-your-adrs">
Install Log4Brains and create your ADRs
&lt;a class="heading-link" href="#install-log4brains-and-create-your-adrs">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>Install &lt;a href="https://github.com/thomvaill/log4brains#what-are-the-prerequisites">Log4Brains&amp;rsquo;s prerequisites&lt;/a> to which I will add &lt;a href="https://code.visualstudio.com/Download">VsCode&lt;/a>, with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint">.md extension&lt;/a>&lt;/li>
&lt;li>Install &lt;a href="https://github.com/thomvaill/log4brains#-getting-started">Log4Brains&lt;/a> and follow the getting started guide. You should be able to preview the site, and create your own ADRs&lt;/li>
&lt;/ul>
&lt;h2 id="commit-and-push-to-azdevops">
Commit and push to AzDevOps
&lt;a class="heading-link" href="#commit-and-push-to-azdevops">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>It can be &lt;a href="https://docs.microsoft.com/en-us/azure/devops/repos/git/create-new-repo?view=azure-devops">a new repository&lt;/a> or the existing repository with the application. Before push ensure the output is being ignored via you .gitignore file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback"># Log4Brains Output
.Log4Brains/
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="add-pipeline-yaml-file">
Add pipeline YAML File
&lt;a class="heading-link" href="#add-pipeline-yaml-file">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>The location doesn&amp;rsquo;t really matter. It can be at / , or you can have a Pipelines or similar folder, the location and name of the file doesn&amp;rsquo;t really matter, what matters is the content:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">trigger: none
pr: none
stages:
- stage: build
displayName: &amp;#39;Build&amp;#39;
jobs:
- job: build
displayName: &amp;#39;Build&amp;#39;
pool:
vmImage: &amp;#39;ubuntu-latest&amp;#39;
steps:
- task: NodeTool@0
inputs:
versionSpec: &amp;#39;14.x&amp;#39;
displayName: &amp;#39;Install Node.js&amp;#39;
- script: |
npm install -g log4brains
log4brains build
displayName: &amp;#39;Install and Build Log4brains&amp;#39;
- task: CopyFiles@2
displayName: &amp;#39;Copy config to $(System.DefaultWorkingDirectory)/.log4brains/out&amp;#39;
inputs:
Contents: staticwebapp.config.json
TargetFolder: &amp;#39;$(System.DefaultWorkingDirectory)/.log4brains/out&amp;#39;
- task: PublishPipelineArtifact@1
inputs:
targetPath: &amp;#39;$(System.DefaultWorkingDirectory)/.log4brains/out&amp;#39;
artifactName: staticSite
- stage: publish
displayName: &amp;#39;Publish&amp;#39;
dependsOn: build
jobs:
- deployment: deployProd
displayName: &amp;#39;Deploy prod&amp;#39;
environment: prod
strategy:
runOnce:
deploy:
steps:
- task: DownloadPipelineArtifact@2
displayName: Download static site artifact
inputs:
artifact: staticSite
path: $(Build.SourcesDirectory)/staticSite
- task: AzureStaticWebApp@0
displayName: Upload to Azure Static WebApp
inputs:
app_location: /staticSite
output_location: &amp;#34;&amp;#34;
env:
azure_static_web_apps_api_token: $(deployment_token)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is a multistage pipeline, where first we build the application, or in this case, run the Log4Brains static site generator to get the html/css output and make it available via Azure DevOps Artifacts, then the second stage pulls the artifact and publishes to Azure Static WebSites.&lt;/p>
&lt;p>On the first stage we install node, install Log4Brains, run the build command to generate the output, then publish the output as an artifact. There is a CopyFiles task before the publish task, this task is to add a special config .json file to the output. This &lt;a href="https://docs.microsoft.com/en-us/azure/static-web-apps/configuration#example-configuration-file">special file&lt;/a> is not needed if you want your ADRs to be publicly available, however if you want to take advantage of the &lt;a href="https://docs.microsoft.com/en-us/azure/static-web-apps/authentication-authorization">Azure Static Website authorization and authentication&lt;/a> capability, you want to copy this file, which gets created in the next step.&lt;/p>
&lt;p>The second stage pulls the artifact and calls the AzureStaticWebApp task to get the site published. The publish token is a pipeline variable that we will set later on the create pipeline step.&lt;/p>
&lt;p>Git commit, git push, to make the file available in the repository.&lt;/p>
&lt;h2 id="adding-the-static-web-page-configuration-file">
Adding the Static Web Page configuration file
&lt;a class="heading-link" href="#adding-the-static-web-page-configuration-file">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>Optional, only if don&amp;rsquo;t want your ADRs to be public. Azure Static Websites provide &lt;a href="https://docs.microsoft.com/en-us/azure/static-web-apps/authentication-authorization">authorization and authentication capabilities&lt;/a> which are configured via the staticwebapp.config.json file, and then adding authorized users via the Azure Portal.&lt;/p>
&lt;p>I created the staticwebapp.config.json file in /, and configured it:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-fallback" data-lang="fallback">{
&amp;#34;routes&amp;#34;: [
{
&amp;#34;route&amp;#34;: &amp;#34;/*&amp;#34;,
&amp;#34;allowedRoles&amp;#34;: [&amp;#34;reader&amp;#34;]
}],
&amp;#34;responseOverrides&amp;#34;: {
&amp;#34;401&amp;#34;: {
&amp;#34;redirect&amp;#34;: &amp;#34;/.auth/login/aad&amp;#34;,
&amp;#34;statusCode&amp;#34;: 302
},
&amp;#34;404&amp;#34;: {
&amp;#34;rewrite&amp;#34;: &amp;#34;/404.html&amp;#34;
}
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>What it says is that every route is only allowed to the &amp;ldquo;reader&amp;rdquo; role, and if a request comes from a not previously authenticated user, the request will be redirected to the Azure Active Directory authentication provider.&lt;/p>
&lt;p>Git commit, git push, to make the file available in the repository.&lt;/p>
&lt;h2 id="create-an-azure-static-website">
Create an Azure Static Website
&lt;a class="heading-link" href="#create-an-azure-static-website">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>No surprises here, &lt;a href="https://docs.microsoft.com/en-us/azure/static-web-apps/publish-devops#create-a-static-web-app">the steps on the portal&lt;/a> are very straight forward, and of course the CLI or a proper infrastructure as code pipeline will work as well.&lt;/p>
&lt;h2 id="create-an-azure-devops-pipeline">
Create an Azure DevOps Pipeline
&lt;a class="heading-link" href="#create-an-azure-devops-pipeline">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>Again, no surprises, &lt;a href="https://docs.microsoft.com/en-us/azure/static-web-apps/publish-devops#create-the-pipeline-task-in-azure-devops">the steps on the guide are very clear&lt;/a>, except for steps 3 and 4, instead of the starter pipeline, select Existing Pipeline and point to the YAML File created earlier, then proceed to the next steps that set the variable with the token and run the pipeline.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/log4brains_pipeline.png" alt="&amp;ldquo;Pipeline Success&amp;rdquo;" title="Pipeline Success">&lt;/p>
&lt;p>The artifacts link available in the pipeline output screen will allow you to verify the contents of the artifact, to ensure the index.html and the staticwebapp.config.json files are present, very useful for troubleshooting.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/log4brains_artifact.png" alt="&amp;ldquo;Artifact details&amp;rdquo;" title="Artifact details">&lt;/p>
&lt;h2 id="invite-users">
Invite users
&lt;a class="heading-link" href="#invite-users">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>Navigate to the Azure Portal, to the Static Web Resource, click on Role management to invite users&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/log4brains_addrolesteps.png" alt="&amp;ldquo;Role management&amp;rdquo;" title="Role management">&lt;/p>
&lt;p>In the invite users dialog, use &amp;lsquo;reader&amp;rsquo; as role. If you use any other role be sure to update the staticwebapp.config.json file accordingly.&lt;/p>
&lt;p>&lt;img src="https://davidtriana.com/images/posts/2021/log4brains_addroledialog.png" alt="&amp;ldquo;Role management&amp;rdquo;" title="Role management">&lt;/p>
&lt;h2 id="enjoy">
Enjoy!
&lt;a class="heading-link" href="#enjoy">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h2>
&lt;p>And with that, the site is available, with user authentication in place. The pipeline trigger can be updated so that every time a new ADR is checked in the pipeline runs automatically.&lt;/p></description></item><item><title>Continuous Integration &amp; Deployment of a NuGet Package with VSTS</title><link>https://davidtriana.com/posts/2016/continuous-integration-deployment-of-a-nuget-package-with-vsts/</link><pubDate>Sat, 26 Nov 2016 03:54:00 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2016/continuous-integration-deployment-of-a-nuget-package-with-vsts/</guid><description>&lt;p>In this post I’ll show the configuration steps to setup a CI/CD in Visual Studio Team System that from a repository build, packages and publishes a NuGet Package.&lt;/p>
&lt;p>To publish a NuGet Package you will need a NuGet server. There are lots of options, and VSTS itself provides one. In my case I setup one using the free Nuget.Server (&lt;a href="http://nugetserver.net/" title="http://nugetserver.net/">http://nugetserver.net/&lt;/a>) and hosted it on a free tier Azure Web Site. Having that, I’m all set.&lt;/p>
&lt;p>First I need the project from which I will then generate the package, so first make sure to have a Visual Studio solution that builds, and that doesn’t have any weird local references since the build will be done by the hosted build service in VSTS. Nuget dependencies are fine, since the CI can take care of that.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Then my project needs to be in a repository in VSTS&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image1.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb1.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>With that, I’m ready to configure the CI/CD build&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image2.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb2.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Leave the defaults in the “Select a template”, be aware however that this screen can change at any time so check the options and selection in your case&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image3.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb3.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>In the “Create new build definition” screen pick the right repository, branch, and check the Continuous integration option if that is really what you want. If you leave it blank you will need to manually start each build, or schedule it in some other way&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image4.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb4.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>VSTS will create a default build definition like this:&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image5.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb5.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Leave only the first two steps, delete the rest.&lt;/p>
&lt;p>To delete a step, first click over it and then on the red arrow to the right next to it:&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image6.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb6.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Click on the green Add build step on top of the steps list and in the Task Catalog dialog select Package and look for the Nuget and click Add&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image7.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb7.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Without closing the dialog, click add on the Nuget Publisher&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image8.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb8.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Then click on Close to dismiss the Task Catalog dialog. Click on the NuGet Publisher step to reveal the configuration. If you are using the Nuget server provided by VSTS then choose “Internal Nuget Feed” and copy/paste the Url provided by the extension.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image9.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb9.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>In my case since I have a external server I left the Feed type as External and clicked on the Manage link to the right of the Url. This is needed only the first time. After the server is setup it will be available in the dropdown control for NuGet Server Endpoint.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image10.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb10.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>The Manage link opens a new page, the “Settings/Services” page. Click on the green New Service Endpoint and choose generic&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image11.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb11.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>In the Add new Generic Connection dialog use a friendly name for Connection Name and fill out the Url and Username and Password if needed. In my case with the Nuget.Server I have I passkey so I typed it there.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image12.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb12.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>After clicking Ok close the Settings page to go back to the Build page, Click on the refresh icon next to the Url to have the server available and select the server.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image13.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb13.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>At this point the Build definition is ready. It must look like this&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image14.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb14.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Click on save and provide a distinctive name for it&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image15.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb15.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>And that’s it!, if you selected the continuous integration the Build will run automatically every time you check in changes in the repo/branch selected at the beginning. To run the build manually click on “Queue build…” and leave the default options. The BuildConfiguration option is particularly important since without it, or misconfigured the build will fail.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image16.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb16.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Moments later a build agent will pick the job and you will be able to see the output of the build tasks in real time&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image17.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb17.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Then the build will finish. If something fails, it will be red, and the logs will help to find the issue, probably some issue with dependencies in the Visual Studio Solution&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image18.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb18.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>To then consume my package, if I haven’t already added my Nuget server I need to do it in the Options screen in Visual Studio. One quick way to get to the right place is to open the Nuget Package Manager and click on the Gear&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image19.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb19.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Then add the server. In my case it looks like this&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image20.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb20.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>And with that I can pick my just created package&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2016/11/image21.png">&lt;img src="https://davidtriana.com/images/posts/2016/11/image_thumb21.png" alt="image" title="image">&lt;/a>&lt;/p></description></item><item><title>Running the Microsoft ALM Training Virtual Machine in Azure April 2015 Edition</title><link>https://davidtriana.com/posts/2015/running-the-alm-virtual-machine-in-azure-april-2015-edition/</link><pubDate>Thu, 09 Apr 2015 21:37:42 +0000</pubDate><author>david@davidtriana.com (David Triana)</author><guid>https://davidtriana.com/posts/2015/running-the-alm-virtual-machine-in-azure-april-2015-edition/</guid><description>&lt;p>Last month I found myself doing ALM training and demos for a couple of customers, of course using the great ALM Virtual Machine by Brian Keller. With laptops having less and less RAM I choose to set it up in the cloud and found a few web pages with the steps to do it, however with Azure evolving every day I felt the need to put out this blog post with the guidance for Azure in April 2015&lt;/p>
&lt;p>Additional to my RAM constrains I also have very limited internet access; some folks suggest to first download the virtual machine locally and then upload to azure. For me that will take at least 3 days watching a download / upload progress bar, so what I did was to do the download in Azure, and then transfer the bits to Azure itself, something like this:&lt;/p>
&lt;ol>
&lt;li>Create an Azure VM&lt;/li>
&lt;li>Add a big disk to that Azure VM (To have space for the download and extraction)&lt;/li>
&lt;li>Download the ALM VM RAR Files&lt;/li>
&lt;li>Extract the RAR Files&lt;/li>
&lt;li>Transfer the .VHD to a new blob storage&lt;/li>
&lt;li>Create a new VM from the VHD&lt;/li>
&lt;li>Create a point to site VPN to avoid exposing the VM directly to the internet&lt;/li>
&lt;li>Connect to the VPN&lt;/li>
&lt;li>Enjoy!&lt;/li>
&lt;/ol>
&lt;p>So let’s go through the steps:&lt;/p>
&lt;h1 id="create-an-azure-vm">
Create an Azure VM
&lt;a class="heading-link" href="#create-an-azure-vm">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Go to the portal, New –&amp;gt; Compute –&amp;gt; Marketplace&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>For this any Windows Virtual Machine should work and I can have just picked the Windows Server 2012R2 image, however I pick the Marketplace to choose the lightest and easiest machine Azure offers me&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image1.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb1.png" alt="image" title="image">&lt;/a> &lt;/p>
&lt;p>Then click Create, pick options and Create. In my case I make sure to pick the right subscription, pick my closest datacenter and a very fast tier.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image2.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb2.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>When the VM is ready, add a new disk to it.&lt;/p>
&lt;h1 id="add-a-big-disk-to-the-vm">
Add a big disk to the VM
&lt;a class="heading-link" href="#add-a-big-disk-to-the-vm">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>From the portal click on the VM or browse for it and pick all settings, disks, attach new and choose the same storage account and container as the one for the VM. Adjust the size and cache and click Ok.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image3.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb3.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>RDP to the machine to attach the disk&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image4.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb4.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Open Computer Management and accept the suggestion&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image5.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb5.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Right click the newly created disk, choose New Simple Volume and follow the Wizard to format the disk&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image6.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb6.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Now we have a VM with enough space to fit the downloaded RAR files and then extract them, so lets do it&lt;/p>
&lt;h1 id="download-the-alm-vm-rar-files">
Download the ALM VM RAR Files
&lt;a class="heading-link" href="#download-the-alm-vm-rar-files">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>In this step I really hate to use Free Download Manager and I spent (wasted) half a day setting up a powershell script to do the same. In the end, FDM does the job and do it very well despite the horrible user interface and installer, so for this step just follow Brian’s guide:&lt;/p>
&lt;p>&lt;a href="http://aka.ms/ALMVMs" title="http://aka.ms/ALMVMs">http://aka.ms/ALMVMs&lt;/a>&lt;/p>
&lt;p>Install FDM&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image7.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb7.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Copy the URLs from Brian’s page to the clipboard&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image8.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb8.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Open FDM and set the download folder to the new disk&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image9.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb9.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>choose import from clipboard&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image10.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb10.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Let it do its thing&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image11.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb11.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>When the download finishes, and in my case it took something like 5 minutes, run the .exe that extracts the VHD&lt;/p>
&lt;h1 id="extract-vhd">
Extract VHD
&lt;a class="heading-link" href="#extract-vhd">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image12.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb12.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Meanwhile, install PowerShell, it will be needed to upload the VHD,&lt;/p>
&lt;p>&lt;a href="http://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/" title="http://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/">http://azure.microsoft.com/en-us/documentation/articles/powershell-install-configure/&lt;/a>&lt;/p>
&lt;p>Launch PowerShell&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image13.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb13.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>Connect to the subscription&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image14.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb14.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>If as me you have more that one subscription, make sure to select the one you intend to use&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image15.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb15.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;h1 id="transfer-the-vhd">
Transfer the VHD
&lt;a class="heading-link" href="#transfer-the-vhd">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Make sure that the extraction finished and issue the command to start the upload. For the blob storage URL I used the same container as the one for this VM. The URL can be found on the portal&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image16.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb16.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>The command:&lt;/p>
&lt;p>&lt;code>Add-AzureVhd -Destination &amp;quot;&amp;lt;BlobStorageURL&amp;gt;/&amp;lt;YourImagesFolder&amp;gt;/&amp;lt;VHDName&amp;gt;.vhd&amp;quot; -LocalFilePath &amp;lt;PathToVHDFile&amp;gt;&lt;/code>&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image17.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb17.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>In the screenshot I show the blob storage account as the same of my VM. Later I have to re-do this using another storage account in the standard tier since I created this one on the premium tier and I had a lot of trouble later creating the actual VM.&lt;/p>
&lt;h1 id="convert-to-os-image">
Convert to OS Image
&lt;a class="heading-link" href="#convert-to-os-image">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>After the VHD is uploaded it should be added as an operating system image. In the screenshot is done via PowerShell, it can also be done via the legacy portal&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image18.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb18.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;h1 id="create-the-virtual-machine">
Create the Virtual Machine
&lt;a class="heading-link" href="#create-the-virtual-machine">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Using the just created image, create a new virtual machine. The screenshots are with the old portal, I also did it with PowerShell&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image19.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb19.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image20.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb20.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image21.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb21.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>In the next step it is important to set the machine in a virtual network and remove the public endpoints, why?, because this image has well known usernames and passwords and exposing it to the internet just like that is a bad idea. The recommended way to do it is to leave it on a Virtual Network and then connect via VPN. In this case I used the virtual network from the first virtual machine. That one was created using the preview portal which by default creates an internal network.&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image22.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb22.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;h1 id="create-a-point-to-site-vpn">
Create a point to site VPN
&lt;a class="heading-link" href="#create-a-point-to-site-vpn">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>While the VM get setup, let’s create the VPN. Look for the same network where the VM was located and use the wizard to create a Point to site dynamic VPN. When I took the screenshot Site-To-Site was selected, make sure to select POINT-TO-SITE&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image23.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb23.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>To get the VPN working you need a self signed certificate. If you have visual studio installed it’s easy with the makecert.exe utility. The procedure is available at &lt;a href="https://msdn.microsoft.com/library/azure/dn133792.aspx/" title="https://msdn.microsoft.com/library/azure/dn133792.aspx/">https://msdn.microsoft.com/library/azure/dn133792.aspx/&lt;/a> and looks like this:&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image24.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb24.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image25.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb25.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;h1 id="connect-to-the-vpn">
Connect to the VPN
&lt;a class="heading-link" href="#connect-to-the-vpn">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>Wait for the creation of the gateway, that usually takes a long time, and then download the client, install and connect:&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image26.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb26.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;h1 id="connect-to-the-vm">
Connect to the VM
&lt;a class="heading-link" href="#connect-to-the-vm">
&lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
&lt;span class="sr-only">Link to heading&lt;/span>
&lt;/a>
&lt;/h1>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image27.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb27.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://davidtriana.com/images/posts/2015/04/image28.png">&lt;img src="https://davidtriana.com/images/posts/2015/04/image_thumb28.png" alt="image" title="image">&lt;/a>&lt;/p>
&lt;p>At this point the first Virtual Machine can be deleted. I will however keep the disk with the original VHD as a mean to rollback since here in Azure I don’t have the snapshotting facility provided by HyperV.&lt;/p>
&lt;p>Now let’s do some ALM…&lt;/p></description></item></channel></rss>